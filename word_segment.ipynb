{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "e8f3518d",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy3 in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.4)\n",
      "Requirement already satisfied: dawg2-python>=0.8.0 in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymorphy3) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymorphy3) (2.4.417150.4580142)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pymorphy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "7d1ddaf9",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyenchant in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pyenchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "87418ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pymorphy3\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "import enchant\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "5627b193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'куплюайфон14про'"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file  = open(r\"C:\\Users\\779\\Downloads\\dataset_1937770_3.txt\", mode='r')\n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "lines = lines[1:]\n",
    "lines = [re.sub(r'^\\d+,', '', line).rstrip('\\r\\n') for line in lines]\n",
    "lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46b859",
   "metadata": {},
   "source": [
    "1ый подход, Динамическое программирование без вероятностей, пробегаемся по строке, находим строки, которые можно считать словом(фильтр подбирал руками исходя из того как работал алгоритм), находим разбиение минимизирующее \"стоимость\" разбиения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "ea71f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "signs = {',', '.','\"', '\\'', ':', ';', '(', ')', '[', ']', '=', '+', '-', '*', '&', '^', '%', '$', '#', '@', '!','?'}\n",
    "mph = pymorphy3.MorphAnalyzer()\n",
    "english_dict = enchant.Dict(\"en_US\")\n",
    "BRANDS = {\n",
    "    'iphone', 'samsung', 'google', 'apple', 'android', 'microsoft', 'nike', 'adidas',\n",
    "    'tesla', 'bmw', 'mercedes', 'ikea'\n",
    "}\n",
    "\n",
    "def is_real_word(word, morph = mph, signs = signs):\n",
    "\n",
    "    if word in signs or word.isdigit():\n",
    "        return True\n",
    "\n",
    "    if word.isalpha() and all(ord(c) < 128 for c in word):\n",
    "        return english_dict.check(word.lower()) or word.lower() in BRANDS\n",
    "    \n",
    "    parsed = morph.parse(word)\n",
    "    if not parsed:\n",
    "        return False\n",
    "    \n",
    "    best = parsed[0]\n",
    "    if best.score >= 0.15:\n",
    "        for method in best.methods_stack:\n",
    "            analyzer, dict_word = method[0], method[1]\n",
    "            \n",
    "            if \"DictionaryAnalyzer\" in str(analyzer):\n",
    "                if dict_word.lower() == word.lower():\n",
    "                    return True\n",
    "    return False\n",
    "        \n",
    "    \n",
    "def dinamic_separate(line):\n",
    "    n = len(line)\n",
    "    dp = []\n",
    "    prev = []\n",
    "    for i in range(0,n+1):\n",
    "        if i == 0:\n",
    "            dp.append(0)\n",
    "            prev.append(-1)\n",
    "        else:\n",
    "            dp.append(100000)\n",
    "            prev.append(0)\n",
    "            for j in range(i):\n",
    "                word = line[j:i]\n",
    "                if is_real_word(word):\n",
    "                    if dp[j] + 1 < dp[i]:  #стоимость разбиения = 1 сравниваем что выгоднее, разбить строку на j-ом симвле, или все первые i символов считать словом\n",
    "                        dp[i] = dp[j] + 1\n",
    "                        prev[i] = j\n",
    "    positions = []\n",
    "    i = n\n",
    "    while i > 0:\n",
    "        j = prev[i]\n",
    "        if j != -1 and i != j and j != 0:  #\n",
    "            positions.append(j) \n",
    "        i = j\n",
    "    return sorted(positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f6d2c",
   "metadata": {},
   "source": [
    "Сохраняем в csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "735c60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(lines):\n",
    "\n",
    "    df = pd.DataFrame({'id': range(len(lines)), 'input_string': lines})\n",
    "    \n",
    "    df['predicted_positions'] = df['input_string'].apply(\n",
    "        lambda x: dinamic_separate(x)\n",
    "    )\n",
    "    \n",
    "    df = df.drop(columns=['input_string'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "result_df = process_dataset(lines)\n",
    "\n",
    "output_file = \"output.csv\"\n",
    "result_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "90ea0ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[5, 10, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[3, 6, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[4, 11, 13, 20, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[5, 10, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[5, 10]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted_positions\n",
       "0   0          [5, 10, 12]\n",
       "1   1            [3, 6, 7]\n",
       "2   2  [4, 11, 13, 20, 21]\n",
       "3   3          [5, 10, 18]\n",
       "4   4              [5, 10]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1467c21",
   "metadata": {},
   "source": [
    "Значение F1 на платформе: 81.19%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71352e39",
   "metadata": {},
   "source": [
    "Проблема: при ручном подборе score(вероятность того что pymorph3 правильно присвоил tag слову), пришлось допустить \"плохие\" слова: ив(ива), ев(ева), ав(ава) и тд, чтобы не упускать хорошие слова с тем же score: айфон."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "f1c0eaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 11, 13, 16]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinamic_separate(\"купитьайфон14промакс\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "7be7a71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6, 13]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinamic_separate(\"книгавхорошемсостоянии\") #тут видно что алгоритм неправильно разбил - книг ав хорошем состоянии, но стоимость разбиения та же"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d063fb9",
   "metadata": {},
   "source": [
    "Чтобы попытаться побороться с проблемой(разбиваем строку на \"странные\" слова), изменил функцию стоимости (теперь это не просто число пробелов, а -сумма логарифмов вероятностей). Для этого нужны вероятности, я использую словарь с частотами, отдельно вероятностную модель не обучаю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "3a7388e4",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordfreq in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: ftfy>=6.1 in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordfreq) (6.3.1)\n",
      "Requirement already satisfied: langcodes>=3.0 in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordfreq) (3.5.0)\n",
      "Requirement already satisfied: locate<2.0.0,>=1.1.1 in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordfreq) (1.1.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordfreq) (1.1.1)\n",
      "Requirement already satisfied: regex>=2023.10.3 in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordfreq) (2024.11.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\779\\appdata\\roaming\\python\\python311\\site-packages (from ftfy>=6.1->wordfreq) (0.2.13)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langcodes>=3.0->wordfreq) (1.3.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\779\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from language-data>=1.2->langcodes>=3.0->wordfreq) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "93122426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordfreq import word_frequency\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "df4caea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0427"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency(\"в\", \"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "bf4fc9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cost(word):\n",
    "    \n",
    "    word = word.lower()\n",
    "    \n",
    "    if word in BRANDS:\n",
    "        return 0.01\n",
    "    \n",
    "    if word.isdigit():\n",
    "        return -math.log(0.001) / (len(word) + 0.01)\n",
    "    #для чисел, чтобы последовательность цифр не разбивалась, нужно чтобы длинное число было \"выгоднее\" чем несколько отдельных подряд идущих цифр\n",
    "    \n",
    "    if word.isalpha() and all(ord(c) < 128 for c in word) and english_dict.check(word.lower()):\n",
    "        return word_frequency(word, \"en\")\n",
    "    \n",
    "    if word.isalpha() and all(ord(c) < 128 for c in word):\n",
    "        return 250 / (len(word) + 0.01)\n",
    "    #В случае если не могли найти английское слово лучше просто отделить эту последовательность символов, но алгоритм за такое штрафуем\n",
    "            \n",
    "    prob = word_frequency(word, 'ru')\n",
    "    \n",
    "    if prob > 0:\n",
    "        return -math.log(prob)\n",
    "    elif is_real_word(word):\n",
    "        return 15\n",
    "    return 100  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "e1eceb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.09701168666918"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cost('книга')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#тут алгоритм почти не меняется, раньше стоимость cost слова был всегда равен 1, тут он вычисляется на основе частот\n",
    "def dinamic_separate_freq(line):\n",
    "    n = len(line)\n",
    "    dp = []\n",
    "    prev = []\n",
    "    for i in range(0, n + 1):\n",
    "        if i == 0:\n",
    "            dp.append(0)\n",
    "            prev.append(-1)\n",
    "        else:\n",
    "            dp.append(100000)  \n",
    "            prev.append(0)\n",
    "            for j in range(i):\n",
    "                word = line[j:i]\n",
    "                cost = word_cost(word) \n",
    "                if dp[j] + cost < dp[i]:\n",
    "                    dp[i] = dp[j] + cost\n",
    "                    prev[i] = j\n",
    "\n",
    "    positions = []\n",
    "    i = n\n",
    "    while i > 0:\n",
    "        j = prev[i]\n",
    "        if j != -1 and i != j and j != 0:\n",
    "            positions.append(j)\n",
    "        i = j\n",
    "    return sorted(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "c29ba3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 13]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinamic_separate_freq(\"книгавхорошемсостоянии\") #правильно разбили"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "f8b13b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 11, 13, 16]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinamic_separate_freq(\"купитьайфон14промакс\") #тут тоже верно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "17832d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(lines):\n",
    "    \"\"\"\n",
    "    Обрабатывает массив строк, добавляет id и predicted_positions, возвращает DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'id': range(len(lines)), 'input_string': lines})\n",
    "    \n",
    "    df['predicted_positions'] = df['input_string'].apply(\n",
    "        lambda x: dinamic_separate_freq(x)\n",
    "    )\n",
    "    \n",
    "    df = df.drop(columns=['input_string'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "result_df = process_dataset(lines)\n",
    "\n",
    "output_file = \"output2.csv\"\n",
    "result_df.to_csv(output_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931560b",
   "metadata": {},
   "source": [
    "Замечание: метод is_real_word достаточно медленный, он замедляет работу метода с 5сек до минуты, но улучшает разбиение (без него алгоритм предпочитает не разбивать длинные строки, изначально is_real_word не использовался, алгоритм выполнился за 5 секунд, но в выводе я заметил очевидные ошибки)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f41baf",
   "metadata": {},
   "source": [
    "Значение F1 - 90.76% против 81.19% в алгоритме без частот"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
